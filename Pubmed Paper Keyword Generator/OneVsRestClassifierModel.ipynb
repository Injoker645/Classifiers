{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2f4173fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "from functools import reduce\n",
    "import re\n",
    "import collections\n",
    "import numpy as np\n",
    "\n",
    "import nltk\n",
    "#nltk.download('stopwords')\n",
    "#nltk.download('wordnet')\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import sent_tokenize\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "stopword = set(stopwords.words('english'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "93c977e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"MLproj.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "32da3764",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>abstract</th>\n",
       "      <th>tags</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>real-world experience covid-19 including direc...</td>\n",
       "      <td>['Aged' 'Aged, 80 and over'\\n 'Antibodies, Mon...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>successful outcome pre-engraftment covid-19 hc...</td>\n",
       "      <td>['COVID-19*' 'Hematopoietic Stem Cell Transpla...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>impact covid-19 oncology professionals-one yea...</td>\n",
       "      <td>['Burnout, Professional* / epidemiology' 'COVI...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>icu admission mortality classifier covid-19 pa...</td>\n",
       "      <td>['Bayes Theorem' 'COVID-19*' 'Hospitalization'...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>clinical evaluation nasopharyngeal midturbinat...</td>\n",
       "      <td>['COVID-19 Testing' 'COVID-19* / diagnosis' 'H...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5468</th>\n",
       "      <td>5468</td>\n",
       "      <td>hypersensitivity reaction vaccine current evid...</td>\n",
       "      <td>['Anaphylaxis* / chemically induced' 'COVID-19...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5469</th>\n",
       "      <td>5469</td>\n",
       "      <td>rooming-in breastfeeding neonatal follow-up in...</td>\n",
       "      <td>['Breast Feeding*' 'COVID-19*' 'Female' 'Follo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5470</th>\n",
       "      <td>5470</td>\n",
       "      <td>acute abducens nerve palsy following second do...</td>\n",
       "      <td>['Abducens Nerve Diseases* / chemically induce...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5471</th>\n",
       "      <td>5471</td>\n",
       "      <td>planning implementing protocol psychosocial in...</td>\n",
       "      <td>['COVID-19*' 'Delivery of Health Care' 'Humans...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5472</th>\n",
       "      <td>5472</td>\n",
       "      <td>prolonged corrected qt interval hospitalized p...</td>\n",
       "      <td>['COVID-19*' 'Electrocardiography' 'Humans'\\n ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5473 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Unnamed: 0                                           abstract  \\\n",
       "0              0  real-world experience covid-19 including direc...   \n",
       "1              1  successful outcome pre-engraftment covid-19 hc...   \n",
       "2              2  impact covid-19 oncology professionals-one yea...   \n",
       "3              3  icu admission mortality classifier covid-19 pa...   \n",
       "4              4  clinical evaluation nasopharyngeal midturbinat...   \n",
       "...          ...                                                ...   \n",
       "5468        5468  hypersensitivity reaction vaccine current evid...   \n",
       "5469        5469  rooming-in breastfeeding neonatal follow-up in...   \n",
       "5470        5470  acute abducens nerve palsy following second do...   \n",
       "5471        5471  planning implementing protocol psychosocial in...   \n",
       "5472        5472  prolonged corrected qt interval hospitalized p...   \n",
       "\n",
       "                                                   tags  \n",
       "0     ['Aged' 'Aged, 80 and over'\\n 'Antibodies, Mon...  \n",
       "1     ['COVID-19*' 'Hematopoietic Stem Cell Transpla...  \n",
       "2     ['Burnout, Professional* / epidemiology' 'COVI...  \n",
       "3     ['Bayes Theorem' 'COVID-19*' 'Hospitalization'...  \n",
       "4     ['COVID-19 Testing' 'COVID-19* / diagnosis' 'H...  \n",
       "...                                                 ...  \n",
       "5468  ['Anaphylaxis* / chemically induced' 'COVID-19...  \n",
       "5469  ['Breast Feeding*' 'COVID-19*' 'Female' 'Follo...  \n",
       "5470  ['Abducens Nerve Diseases* / chemically induce...  \n",
       "5471  ['COVID-19*' 'Delivery of Health Care' 'Humans...  \n",
       "5472  ['COVID-19*' 'Electrocardiography' 'Humans'\\n ...  \n",
       "\n",
       "[5473 rows x 3 columns]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "37db027d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_punctuation(text):\n",
    "    \n",
    "    # punctuations except -  \n",
    "    punc ='''?!.,:;_—[](){}'\"`~|\\/@#$%^&+=*'''\n",
    "    for i in text:\n",
    "        if i in punc:\n",
    "            text = text.replace(i, ' ')            \n",
    "    return text.strip()\n",
    "\n",
    "def preprocess(text):\n",
    "    \n",
    "    # lower casing\n",
    "    text=text.lower()\n",
    "    \n",
    "    # stopword removal\n",
    "    text = [word for word in text.split(' ') if word not in stopword]\n",
    "    text=\" \".join(text)\n",
    "    \n",
    "    # lemmatization\n",
    "    text = [lemmatizer.lemmatize(word) for word in text.split(' ')]\n",
    "    text = \" \".join(text)\n",
    "    \n",
    "    # removing words containing only numbers\n",
    "    text = re.sub(r'\\s[0-9]+\\s', '', text)\n",
    "    \n",
    "    # remove extra spaces\n",
    "    text = re.sub(\"\\s\\s+\", \" \", text)   \n",
    "    return text.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "20192fd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['title']=df['title'].apply(remove_punctuation)\n",
    "df['title']=df['title'].apply(preprocess)\n",
    "\n",
    "df['abstract']=df['abstract'].apply(remove_punctuation)\n",
    "df['abstract']=df['abstract'].apply(preprocess)\n",
    "\n",
    "df['tags']=df['tags'].apply(preprocess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "0c244db5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>abstract</th>\n",
       "      <th>tags</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>real-world experience covid-19 including direc...</td>\n",
       "      <td>article summarizes experience covid-19 patient...</td>\n",
       "      <td>['aged', 'aged,over', 'antibodies, monoclonal,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>successful outcome pre-engraftment covid-19 hc...</td>\n",
       "      <td>coronavirus disease covid-19 caused severe acu...</td>\n",
       "      <td>['covid-19*', 'hematopoietic stem cell transpl...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>impact covid-19 oncology professionals-one yea...</td>\n",
       "      <td>background covid-19 significant impact well-be...</td>\n",
       "      <td>['burnout, professional* / epidemiology', 'cov...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>icu admission mortality classifier covid-19 pa...</td>\n",
       "      <td>coronavirus disease covid-19 caused severe acu...</td>\n",
       "      <td>['bayes theorem', 'covid-19*', 'hospitalizatio...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>clinical evaluation nasopharyngeal midturbinat...</td>\n",
       "      <td>setting supply chain shortage nasopharyngeal n...</td>\n",
       "      <td>['covid-19 testing', 'covid-19* / diagnosis', ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5468</th>\n",
       "      <td>hypersensitivity reaction vaccine current evid...</td>\n",
       "      <td>first report hypersensitivity reaction followi...</td>\n",
       "      <td>['anaphylaxis* / chemically induced', 'covid-1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5469</th>\n",
       "      <td>rooming-in breastfeeding neonatal follow-up in...</td>\n",
       "      <td>introduction due growing evidence suggesting c...</td>\n",
       "      <td>['breast feeding*', 'covid-19*', 'female', 'fo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5470</th>\n",
       "      <td>acute abducens nerve palsy following second do...</td>\n",
       "      <td>author report case otherwise healthy 65-year-o...</td>\n",
       "      <td>['abducens nerve diseases* / chemically induce...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5471</th>\n",
       "      <td>planning implementing protocol psychosocial in...</td>\n",
       "      <td>present study aim plan protocol providing psyc...</td>\n",
       "      <td>['covid-19*', 'delivery health care', 'humans'...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5472</th>\n",
       "      <td>prolonged corrected qt interval hospitalized p...</td>\n",
       "      <td>objective evaluate association prolonged corre...</td>\n",
       "      <td>['covid-19*', 'electrocardiography', 'humans',...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5473 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  title  \\\n",
       "0     real-world experience covid-19 including direc...   \n",
       "1     successful outcome pre-engraftment covid-19 hc...   \n",
       "2     impact covid-19 oncology professionals-one yea...   \n",
       "3     icu admission mortality classifier covid-19 pa...   \n",
       "4     clinical evaluation nasopharyngeal midturbinat...   \n",
       "...                                                 ...   \n",
       "5468  hypersensitivity reaction vaccine current evid...   \n",
       "5469  rooming-in breastfeeding neonatal follow-up in...   \n",
       "5470  acute abducens nerve palsy following second do...   \n",
       "5471  planning implementing protocol psychosocial in...   \n",
       "5472  prolonged corrected qt interval hospitalized p...   \n",
       "\n",
       "                                               abstract  \\\n",
       "0     article summarizes experience covid-19 patient...   \n",
       "1     coronavirus disease covid-19 caused severe acu...   \n",
       "2     background covid-19 significant impact well-be...   \n",
       "3     coronavirus disease covid-19 caused severe acu...   \n",
       "4     setting supply chain shortage nasopharyngeal n...   \n",
       "...                                                 ...   \n",
       "5468  first report hypersensitivity reaction followi...   \n",
       "5469  introduction due growing evidence suggesting c...   \n",
       "5470  author report case otherwise healthy 65-year-o...   \n",
       "5471  present study aim plan protocol providing psyc...   \n",
       "5472  objective evaluate association prolonged corre...   \n",
       "\n",
       "                                                   tags  \n",
       "0     ['aged', 'aged,over', 'antibodies, monoclonal,...  \n",
       "1     ['covid-19*', 'hematopoietic stem cell transpl...  \n",
       "2     ['burnout, professional* / epidemiology', 'cov...  \n",
       "3     ['bayes theorem', 'covid-19*', 'hospitalizatio...  \n",
       "4     ['covid-19 testing', 'covid-19* / diagnosis', ...  \n",
       "...                                                 ...  \n",
       "5468  ['anaphylaxis* / chemically induced', 'covid-1...  \n",
       "5469  ['breast feeding*', 'covid-19*', 'female', 'fo...  \n",
       "5470  ['abducens nerve diseases* / chemically induce...  \n",
       "5471  ['covid-19*', 'delivery health care', 'humans'...  \n",
       "5472  ['covid-19*', 'electrocardiography', 'humans',...  \n",
       "\n",
       "[5473 rows x 3 columns]"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "d26c82e0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"['aged', 'aged,over', 'antibodies, monoclonal, humanized / therapeutic use*', 'antibodies, neutralizing / therapeutic use', 'antigens, viral / analysis', 'covid-19 testing', 'covid-19* / diagnosis', 'covid-19* / therapy', 'hospitals', 'humans', 'middle aged', 'retrospective studies', 'south dakota']\""
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['tags'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "4ad1befb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv(val):\n",
    "    val = val.replace(\"'\",\"\")\n",
    "    val = val.strip('][').split(', ')\n",
    "    return val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "1aca8c11",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['tags'] = df['tags'].apply(conv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "6f5714e7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Aged Aged',\n",
       " '80 and over\\n Antibodies',\n",
       " 'Monoclonal',\n",
       " 'Humanized / therapeutic use*\\n Antibodies',\n",
       " 'Neutralizing / therapeutic use Antigens',\n",
       " 'Viral / analysis\\n COVID-19 Testing COVID-19* / diagnosis COVID-19* / therapy\\n Hospitals Humans Middle Aged Retrospective Studies South Dakota']"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['tags'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "3f005623",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make sure there is no spaces in the empty elements. Example: ' ' -> ''\n",
    "for i in range(len(df)):\n",
    "    for j, word in enumerate(df['tags'][i]):\n",
    "        df['tags'][i][j] = df['tags'][i][j].strip()\n",
    "        \n",
    "# Mark None for the the keyword, covid-19 and humans, since almost all the abstracts have as keyword.\n",
    "# Mark None for the empty elements '' \n",
    "for i in range(len(df)):\n",
    "    for j, word in enumerate(df['tags'][i]):\n",
    "        if word == '':\n",
    "            df['tags'][i][j] = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "58963f74",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Aged Aged\n",
      "80 and over\n",
      " Antibodies\n",
      "Monoclonal\n",
      "Humanized / therapeutic use*\n",
      " Antibodies\n",
      "Neutralizing / therapeutic use Antigens\n",
      "Viral / analysis\n",
      " COVID-19 Testing COVID-19* / diagnosis COVID-19* / therapy\n",
      " Hospitals Humans Middle Aged Retrospective Studies South Dakota\n"
     ]
    }
   ],
   "source": [
    "for n,word in enumerate(df['tags'][0]):\n",
    "    print(df['tags'][0][n])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "d4e6492d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['tags'] = [list(filter(None, df['tags'][i])) for i in range(len(df))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "90ba90ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of total unique tags: 8817\n",
      "100 most common tags: ['Antibodies', 'Adult Aged Aged', 'Attitudes', 'Aged Aged', 'Animals Antibodies', 'Monoclonal', 'Adaptation', 'Adolescent Adult Aged Aged', 'Coronavirus / genetics\\n Spike Glycoprotein', 'Synthetic mRNA Vaccines', 'Adult Antibodies', 'X-Ray Computed', 'Neutralizing Antibodies', 'Coronavirus / chemistry\\n Spike Glycoprotein', 'COVID-19* Education', 'Coronavirus', 'Medical*', 'Administration', 'Neutralizing / immunology Antibodies', 'Adult Aged Antibodies', 'Nursing*', 'Neutralizing / immunology\\n Antibodies', 'Medical', 'Coronavirus / genetics', 'Burnout', 'Coronavirus / metabolism', 'Neutralizing / immunology*\\n Antibodies', 'Coronavirus / immunology', 'Neutralizing / blood\\n Antibodies', 'Coronavirus / genetics*\\n Spike Glycoprotein', 'Nursing', 'Mechanical', '80 and over\\n Antibodies', 'Viral / blood\\n Antibodies', 'Coronavirus / immunology*', 'Coronavirus / immunology\\n Spike Glycoprotein', 'Aged Antibodies', 'Coronavirus / chemistry*\\n Spike Glycoprotein', 'Left', 'Human* / epidemiology\\n Influenza', 'Psychological / epidemiology', 'Antigens', 'Lymphocytic', 'Chronic', 'Antigen', 'Coronavirus / immunology*\\n Spike Glycoprotein', 'COVID-19* Child Child', 'Thrombocytopenic', 'Neutralizing / immunology* Antibodies', 'Aged', 'Neutralizing / blood*\\n Antibodies', 'Multiple', 'Monoclonal / immunology\\n Antibodies', 'Adjuvants', '80 and over Antibodies', 'Leukocytoclastic', 'Viral / blood Antibodies', 'Analgesics', 'Coronavirus / metabolism*', 'Inbred C57BL Mice', 'Humanized / therapeutic use*\\n Antibodies', 'X-Ray Computed / methods', 'Adolescent Antibodies', 'Viral SARS-CoV-2', 'Human', 'Synthetic\\n mRNA Vaccines', 'COVID-19* Diabetes Mellitus', 'Neutralizing / blood Antibodies', 'COVID-19* Humans Pandemics SARS-CoV-2', 'Inactivated', 'Artificial SARS-CoV-2', 'Neutralizing / blood* Antibodies', 'Coronavirus / metabolism* Virus Internalization', 'COVID-19* / therapy Humans Immunization', 'Psychological', 'Post-Traumatic* / epidemiology', 'COVID-19* Emergency Service', 'Inbred BALB C\\n Mice', 'Humanized Antibodies', 'Type 2* / complications\\n Diabetes Mellitus', 'COVID-19* Deep Learning* Humans Neural Networks', 'Monoclonal / therapeutic use\\n Antibodies', 'Synthetic / administration &amp; dosage\\n Vaccines', 'COVID-19* Child', 'Virus / genetics Receptors', 'Adolescent Adult Age Distribution Aged Aged', 'COVID-19* Diagnostic Tests', 'Replacement', 'Arrhythmias', 'COVID-19* Humans RNA', 'Cellular / immunology* Immunity', 'Secondary Immunogenicity', 'Newborn\\n Intensive Care Units', 'Cellular Immunity', 'Viral / genetics SARS-CoV-2', 'Viral / biosynthesis Antibodies', 'Neutralizing / chemistry\\n Antibodies', 'Arthritis', 'Newborn\\n Infectious Disease Transmission', 'Professional* / epidemiology\\n Burnout']\n"
     ]
    }
   ],
   "source": [
    "# Generate a list of all the tags \n",
    "tags_list = []\n",
    "for i in range(len(df)):\n",
    "    tags_list = tags_list + df['tags'][i]\n",
    "\n",
    "# Counts for each unique keyword\n",
    "counter=collections.Counter(tags_list)\n",
    "print('Number of total unique tags: {}'.format(len(counter)))\n",
    "\n",
    "# Pull the 20 most common words\n",
    "most_common_words= [word for word, word_count in collections.Counter(tags_list).most_common(100)]\n",
    "print('100 most common tags: {}'.format(most_common_words))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "69ab2758",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of total abstracts after removal: 1060\n"
     ]
    }
   ],
   "source": [
    "# Keep only the most common tags and if abstract doesn't include any of the common tags, remove completely\n",
    "for i in range(len(df)):\n",
    "    for j, word in enumerate(df['tags'][i]):\n",
    "        if word not in most_common_words:\n",
    "            df['tags'][i][j] = None\n",
    "                 \n",
    "df['tags'] = [list(filter(None, df['tags'][i])) for i in range(len(df))]\n",
    "df = df[df['tags'].map(lambda d: len(d)) > 0]\n",
    "df.reset_index(inplace = True, drop = True)\n",
    "\n",
    "print('Number of total abstracts after removal: {}'.format(len(df)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "474ee344",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_extraction.text import CountVectorizer,TfidfTransformer\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.metrics import hamming_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "5dcf53c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y_train_binary shape: (848, 100) \n",
      "y_test_binary shape: (212, 100)\n",
      "\n",
      "y_train_binary array: \n",
      "[[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "  0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "  0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "  0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "  0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "  1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 1 0 0 0 0 0 0 0 0\n",
      "  0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "  0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "  0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "  0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "  0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "  0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "  0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "  0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "  0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "  0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "  0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "  0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "  0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "  0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "  0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]]\n"
     ]
    }
   ],
   "source": [
    "X = np.array(df['abstract'])\n",
    "y = df['tags']\n",
    "\n",
    "# MultiLabelBinarizer is used to transform the tags to a binary matrix for multilabel modeling\n",
    "# Fit all labels to binarizer\n",
    "mlb = MultiLabelBinarizer().fit(y)\n",
    "\n",
    "# Split data into a features matrix and target vector\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state = 9000)\n",
    "\n",
    "# Transform train and test tags into the binary matrix format\n",
    "y_train_binary = mlb.transform(y_train)\n",
    "y_test_binary = mlb.transform(y_test)\n",
    "print('y_train_binary shape: {} \\ny_test_binary shape: {}'.format(y_train_binary.shape, y_test_binary.shape))\n",
    "print()\n",
    "print('y_train_binary array: \\n{}'.format(y_train_binary[:10]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "c6795dfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = CountVectorizer(analyzer = 'word', strip_accents = 'unicode', stop_words = 'english')\n",
    "\n",
    "# Fit and transform the training abstract text and transform the test abstract text\n",
    "X_train_tok = vectorizer.fit_transform(X_train)\n",
    "X_test_tok = vectorizer.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "a302ea65",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transform a count matrix to a normalized tf or tf-idf representation\n",
    "tfidf_transformer = TfidfTransformer()\n",
    "X_train_tfidf = tfidf_transformer.fit_transform(X_train_tok)\n",
    "X_test_tfidf = tfidf_transformer.transform(X_test_tok)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "8068addc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Standard training set score: 1.000\n",
      "Standard test set score: 0.137\n",
      "Hamming loss measure: 0.0123113208\n",
      "\n",
      "Actual labels:\n",
      "1 ('Attitudes',)\n",
      "2 ('Adult Aged Aged',)\n",
      "3 ('Attitudes',)\n",
      "4 ('Coronavirus / immunology',)\n",
      "5 ('Arthritis',)\n",
      "6 ('Adaptation',)\n",
      "7 ('Multiple',)\n",
      "8 ('Coronavirus',)\n",
      "9 ('Coronavirus / genetics\\n Spike Glycoprotein',)\n",
      "10 ('Attitudes',)\n",
      "11 ('Burnout',)\n",
      "12 ('X-Ray Computed',)\n",
      "13 ('Psychological / epidemiology',)\n",
      "14 ('Adaptation',)\n",
      "15 ('Aged Antibodies', 'Coronavirus')\n",
      "16 ('Adult Aged Aged',)\n",
      "17 ('COVID-19* Education',)\n",
      "18 ('Antibodies',)\n",
      "19 ('80 and over\\n Antibodies', 'Aged Aged', 'Monoclonal')\n",
      "20 ('Coronavirus / chemistry\\n Spike Glycoprotein', 'Coronavirus / genetics\\n Spike Glycoprotein', 'Coronavirus / immunology*\\n Spike Glycoprotein', 'Coronavirus / metabolism')\n",
      "21 ('Medical*',)\n",
      "22 ('Burnout',)\n",
      "23 ('COVID-19* Emergency Service',)\n",
      "24 ('Animals Antibodies', 'Neutralizing / blood Antibodies')\n",
      "25 ('Antibodies', 'Coronavirus / genetics')\n",
      "26 ('COVID-19* Humans Pandemics SARS-CoV-2',)\n",
      "27 ('Antibodies',)\n",
      "28 ('Antibodies',)\n",
      "29 ('Replacement',)\n",
      "\n",
      "Predicted labels:\n",
      "1 ('Attitudes',)\n",
      "2 ()\n",
      "3 ('Attitudes',)\n",
      "4 ()\n",
      "5 ()\n",
      "6 ()\n",
      "7 ()\n",
      "8 ()\n",
      "9 ()\n",
      "10 ('Attitudes',)\n",
      "11 ('Burnout',)\n",
      "12 ('X-Ray Computed',)\n",
      "13 ()\n",
      "14 ()\n",
      "15 ()\n",
      "16 ()\n",
      "17 ()\n",
      "18 ()\n",
      "19 ()\n",
      "20 ('Coronavirus / chemistry\\n Spike Glycoprotein',)\n",
      "21 ()\n",
      "22 ()\n",
      "23 ()\n",
      "24 ()\n",
      "25 ()\n",
      "26 ()\n",
      "27 ()\n",
      "28 ()\n",
      "29 ()\n"
     ]
    }
   ],
   "source": [
    "# Look at the C parameter\n",
    "clf = OneVsRestClassifier(LinearSVC(max_iter=700))\n",
    "clf.fit(X_train_tfidf,y_train_binary)\n",
    "y_preds_binary = clf.predict(X_test_tfidf)\n",
    "\n",
    "actual_key = mlb.inverse_transform(y_test_binary)[1:30]\n",
    "predicted_key = mlb.inverse_transform(y_preds_binary)[1:30]\n",
    "\n",
    "print(\"Standard training set score: {:.3f}\".format(clf.score(X_train_tfidf, y_train_binary)))\n",
    "print(\"Standard test set score: {:.3f}\".format(clf.score(X_test_tfidf, y_test_binary)))\n",
    "print(\"Hamming loss measure: {:.10f}\".format(hamming_loss(y_test_binary,y_preds_binary)))\n",
    "\n",
    "print()\n",
    "count = 0\n",
    "print('Actual labels:')\n",
    "for label in actual_key:\n",
    "    count += 1\n",
    "    print(count, label)\n",
    "    \n",
    "print()\n",
    "\n",
    "count = 0\n",
    "print('Predicted labels:')\n",
    "for label in predicted_key:\n",
    "    count +=1\n",
    "    print(count, label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "10c73058",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ........ (step 1 of 3) Processing vectorizer, total=   0.1s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n",
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   0.3s\n",
      "Standard training set score: 1.000\n",
      "Standard test set score: 0.137\n",
      "Hamming loss measure: 0.0123113208\n",
      "\n",
      "Actual labels:\n",
      "1 ('Attitudes',)\n",
      "2 ('Adult Aged Aged',)\n",
      "3 ('Attitudes',)\n",
      "4 ('Coronavirus / immunology',)\n",
      "5 ('Arthritis',)\n",
      "6 ('Adaptation',)\n",
      "7 ('Multiple',)\n",
      "8 ('Coronavirus',)\n",
      "9 ('Coronavirus / genetics\\n Spike Glycoprotein',)\n",
      "10 ('Attitudes',)\n",
      "11 ('Burnout',)\n",
      "12 ('X-Ray Computed',)\n",
      "13 ('Psychological / epidemiology',)\n",
      "14 ('Adaptation',)\n",
      "15 ('Aged Antibodies', 'Coronavirus')\n",
      "16 ('Adult Aged Aged',)\n",
      "17 ('COVID-19* Education',)\n",
      "18 ('Antibodies',)\n",
      "19 ('80 and over\\n Antibodies', 'Aged Aged', 'Monoclonal')\n",
      "20 ('Coronavirus / chemistry\\n Spike Glycoprotein', 'Coronavirus / genetics\\n Spike Glycoprotein', 'Coronavirus / immunology*\\n Spike Glycoprotein', 'Coronavirus / metabolism')\n",
      "21 ('Medical*',)\n",
      "22 ('Burnout',)\n",
      "23 ('COVID-19* Emergency Service',)\n",
      "24 ('Animals Antibodies', 'Neutralizing / blood Antibodies')\n",
      "25 ('Antibodies', 'Coronavirus / genetics')\n",
      "26 ('COVID-19* Humans Pandemics SARS-CoV-2',)\n",
      "27 ('Antibodies',)\n",
      "28 ('Antibodies',)\n",
      "29 ('Replacement',)\n",
      "\n",
      "Predicted labels:\n",
      "1 ('Attitudes',)\n",
      "2 ()\n",
      "3 ('Attitudes',)\n",
      "4 ()\n",
      "5 ()\n",
      "6 ()\n",
      "7 ()\n",
      "8 ()\n",
      "9 ()\n",
      "10 ('Attitudes',)\n",
      "11 ('Burnout',)\n",
      "12 ('X-Ray Computed',)\n",
      "13 ()\n",
      "14 ()\n",
      "15 ()\n",
      "16 ()\n",
      "17 ()\n",
      "18 ()\n",
      "19 ()\n",
      "20 ('Coronavirus / chemistry\\n Spike Glycoprotein',)\n",
      "21 ()\n",
      "22 ()\n",
      "23 ()\n",
      "24 ()\n",
      "25 ()\n",
      "26 ()\n",
      "27 ()\n",
      "28 ()\n",
      "29 ()\n"
     ]
    }
   ],
   "source": [
    "classifier2 = Pipeline([\n",
    "    ('vectorizer', CountVectorizer(analyzer = 'word', strip_accents = 'unicode', stop_words = 'english')),\n",
    "    ('tfidf', TfidfTransformer()),\n",
    "    ('clf', OneVsRestClassifier(LinearSVC(max_iter = 2000)))], verbose = True)\n",
    "\n",
    "classifier2 = classifier2.fit(X_train, y_train_binary)\n",
    "y_preds_binary_2 = classifier2.predict(X_test)\n",
    "\n",
    "actual_2 = mlb.inverse_transform(y_test_binary)[1:30]\n",
    "predicted_2 = mlb.inverse_transform(y_preds_binary_2)[1:30]\n",
    "\n",
    "print(\"Standard training set score: {:.3f}\".format(classifier2.score(X_train, y_train_binary)))\n",
    "print(\"Standard test set score: {:.3f}\".format(classifier2.score(X_test, y_test_binary)))\n",
    "print(\"Hamming loss measure: {:.10f}\".format(hamming_loss(y_test_binary,y_preds_binary_2)))\n",
    "\n",
    "print()\n",
    "count = 0\n",
    "print('Actual labels:')\n",
    "for label in actual_2:\n",
    "    count += 1\n",
    "    print(count, label)\n",
    "    \n",
    "print()\n",
    "\n",
    "count = 0\n",
    "print('Predicted labels:')\n",
    "for label in predicted_2:\n",
    "    count +=1\n",
    "    print(count, label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "321fc726",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "32075a8a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "sklearn.pipeline.Pipeline"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(classifier2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99bc976d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
